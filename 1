import pandas as pd
from sklearn.preprocessing import OneHotEncoder
import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Flatten
from keras.utils import to_categorical
from sklearn.model_selection import KFold
df = pd.read_excel(r'D:\Career\wrtiting paper\first paper\FGAP\neural network\New folder\data.xlsx')
second_row = df.iloc[0,3:]
second_row_list = second_row.tolist()
first_row = []
for i in second_row_list:
    first_row.append(i)
print(len(first_row))
first_row[0]
column1 = df.loc[1:298 ,'Unnamed: 2']
column1_list = column1.tolist()
first_column = []
for i in column1_list:
    first_column.append(i)
print(len(first_column))
column1 = df.loc[1:298 ,'Unnamed: 2']
column1_list = column1.tolist()
first_column = []
for i in column1_list:
    first_column.append(i)
print(len(first_column))
first_column[0]
input_list = []
num_vars = 298
for i in range(1, num_vars+1):
    var_name = f"input_{i}"
    exec(f"{var_name} = []")
    input_list.append(eval(var_name))
print(input_list)
#for i in range(1, num_vars+1):
   # var_name = f"label_{i}"
   # print(f"{var_name}: {eval(var_name)}")
output_list = []
num_vars = 298
for i in range(1, num_vars+1):
    var_name = f"output_{i}"
    exec(f"{var_name} = []")
    output_list.append(eval(var_name))
print(output_list)
#for i in range(1, num_vars+1):
   # var_name = f"feature_{i}"
   # print(f"{var_name}: {eval(var_name)}")
indx = 0
col_indx = 0
input_indx = 0
while indx < 298:
  for i in first_row:
    input_list[input_indx].append(first_column[col_indx]+','+i)
  col_indx += 1
  input_indx += 1
  indx += 1


    
input_list[297][1]
new_input_data = []

for sublist in input_list:
    new_sublist = []
    for i, element in enumerate(sublist):
        new_sublist.append([float(x) for x in element.split(',')])
    new_input_data.append(new_sublist)
new_input_data[1][5]
third_row = df.iloc[1,3:]
third_row_list = third_row.tolist()
third_row = []
for i in third_row_list:
    third_row.append(i)
print(len(third_row))
print(third_row)
third_row[0]
row_indx = 1
indx = 0
while indx < 298:
    row = df.iloc[row_indx,3:]
    row_lst = row.tolist()
    for i in row_lst:
        output_list[indx].append(i)
    row_indx += 1
    indx += 1
    
def one_hot_encode(sublist_list):
    encoded_data = []
    feature_names = []
    
    unique_elements = set([item for sublist in sublist_list for item in sublist])
    encoding_dict = {element: i for i, element in enumerate(unique_elements)}
    
    for sublist in sublist_list:
        encoded_sublist = []
        for element in sublist:
            encoding = [0] * len(unique_elements)
            encoding[encoding_dict[element]] = 1
            encoded_sublist.append(encoding)
        encoded_data.append(encoded_sublist)
    for element in unique_elements:
        feature_names.append(element)
    return encoded_data, feature_names
encoded_list, feature_list = one_hot_encode(output_list)
feature_list[0]
print(encoded_list[0])
input_data = np.reshape(new_input_data , (298*298, 10))
output_data = np.reshape(encoded_list , (298*298, 33))
print(input_data)
print(output_data)
input_data = np.reshape(new_input_data , (298*298, 10))
output_data = np.reshape(encoded_list , (298*298, 33))

model = Sequential()
model.add(Dense(64, input_shape=(10,), activation='relu'))
model.add(Dense(33, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam')


model.fit(input_data, output_data , epochs=40)
input_data = np.array([[-3.0, -1.0, -1.0, -3.0, -2.0, -3.0, -1.0, -1.0, -2.0, -2.0]])
input_data = np.reshape(input_data, (1, 10))

predictions = model.predict(input_data)


print(predictions)
predicted_class = model.predict(input_data.reshape(1, 10))
predicted_class_index = predicted_class.argmax()
print("Predicted class index:", predicted_class_index)
 
